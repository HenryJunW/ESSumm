Should I go first , with the uh , um , data .
So . On Friday we had our wizard test data test and um {vocalsound} these are some of the results .
This was the introduction .
so I asked uh Litonya . just on the spur of the moment , and she was uh kind enough to uh serve as the first subject .
So , this is what she saw as part of {disfmarker} as uh for instr introduction ,
this is what she had to read {pause} aloud .
this was the uh first three tasks she had to {disfmarker} to master after she called the system ,
I should say the system was supposed to break down and then um these were the remaining three tasks that she was going to solve , with a human {disfmarker}
There are {disfmarker} here are uh the results .
The reading was five minutes , exactly .
Like , there was a wizard for both uh {disfmarker} both parts ,
It was bo it both times the same person .
One time , pretending to be a system ,
one time , to {disfmarker} pretending to be a human , which is actually not pretending .
OK , the uh lessons learned .
The reading needs to be shorter .
Five minutes is just too long .
And we need a better introduction for the wizard .
That is something that Fey actually thought of a {disfmarker} in the last second that sh the system should introduce itself , when it 's called .
And um , um , another suggestion , by Liz , was that we uh , through subjects , switch the tasks .
So when {disfmarker} when they have task - one with the computer , the next person should have task - one with a human , and so forth .
So we get nice um data for that .
Um , we have to refine the tasks more and more , which of course we haven't done at all , so far , in order to avoid this rephrasing ,
so where , even though w we don't tell the person " ask {pause} blah - blah - blah - blah - blah "
And uh my suggestion is of course we {disfmarker} we keep the wizard , because I think she did a wonderful job ,
in the sense that she responded quite nicely to things that were not asked for ,
So {pause} first of all , I agree that um we should hire Fey , and start paying her .
Probably pay for the time she 's put in as well .
Um {pause} And also if she 's willing to take on the job of organizing all those subjects and stuff that would be wonderful .
Um . Now , {pause} I signed us up for the Wednesday slot , and part of what we should do is this .
my idea on that was {pause} uh , partly we 'll talk about system stuff for the computer scientists ,
but partly I did want it to get the linguists involved in some of this issue about what the task is and all {disfmarker} um you know , what the dialogue is , and what 's going on linguistically ,
because to the extent that we can get them contributing ,
maybe we can get some of the linguists sufficiently interested that they 'll help us with it ,
So my idea on {disfmarker} on Wednesday is partly to uh {disfmarker}
you {disfmarker} I mean , what you did today would {disfmarker} i is just fine .
You just uh do " this is what we did , and here 's the {pause} thing , and here 's s some of the dialogue and {disfmarker} and so forth . "
and where the pieces are and stuff like that .
and where we think the belief - nets fit in
But then , the other thing of course is we should um give the computer scientists some idea of {disfmarker} of what 's going on with the system design ,
So , what I did for this {disfmarker} this is {disfmarker} uh , a pedagogical belief - net
because I was {disfmarker} I {disfmarker} I took {disfmarker} I tried to conceptually do what you were talking about with the nodes that you could expand out {disfmarker}
you don't have to make any new {pause} uh PowerPoint or anything .
So basically all I did was I took the last {pause} belief - net
and I grouped things according to what {disfmarker} how I thought they would fit in to uh image schemas that would be related .
Um , you know , we have {disfmarker} we have the concept of what their intention was , whether they were trying to tour or do business or whatever ,
Alright , so I understand what 's {disfmarker} what you got .
I don't yet understand {pause} how you would use it .
Well , this is not a working Bayes - net .
So , so if you {disfmarker} if we made {disfmarker} if we wanted to make it into a {disfmarker} a real uh Bayes - net ,
you know , actually f uh , fill it @ @ in , then uh {disfmarker}
So we 'd have to get rid of this and connect these things directly to the Mode .
And {disfmarker} and uh {disfmarker} Bhaskara and I was talking about this a little earlier today {disfmarker}
Well , here 's the problem .
is , if we just do this , we could wind up with a huge uh , combinatoric input to the Mode thing .
I just {disfmarker} uh it 's hard for me to imagine how he could get around that .
There {disfmarker} there are a variety of ways of doing it .
Uh . Let me just mention something that I don't want to pursue today
which is there are technical ways of doing it ,
So it 's possible that we could do something like a summary node of some sort that {disfmarker}
I mean , not necessarily in th in this meeting , but to try to informally think about what the decision variables are .
So what I was gonna say is {disfmarker} is maybe a good at this point is to try to informally {disfmarker}
And the other trick , which is not a technical trick , it 's kind of a knowledge engineering trick , is to make the n {pause} each node sufficiently narrow that you don't get this combinatorics .
So that if you decided that you could characterize the decision as a trade - off between three factors , whatever they may be ,
So that y so that , you know , you can sort of try to do a knowledge engineering thing
given that we 're not gonna screw with the technology and just always use uh sort of orthodox Bayes - nets , then we have a knowledge engineering little problem of how do we do that .
I mean , so uh , Robert has thought about this problem f for a long time , cuz he 's had these examples kicking around ,
so he may have some good intuition about you know , what are the crucial things .
And um this is about as much as we can do if we don't w if we want to avoid uh uh a huge combinatorial explosion where we specify " OK , if it 's this and this but that is not the case " , and so forth , it just gets really really messy .
So this is just based on this one {disfmarker} um , on this one feature ,
So , I {disfmarker} I do understand that uh you can take the M - three - L and add not {disfmarker} and it w
we have to add , you know , not too much about um object types and stuff ,
and what I think you did is add some rules of the style that are already there that say " If it 's of type " Landmark " , then you take {disfmarker} you 're gonna take a picture of it . "
Ev - every landmark you take a picture of ,
Every public place you enter , and statue you want to go as near as possible .
Uh , and certainly you can add rules like that to the existing SmartKom system .
Add extra properties ,
a deterministic rule for every property
Uh Now , if that 's all you 're doing , then you can get the types from the ontology ,
So we don't {disfmarker} we don't use the discourse , we don't use the context , we don't do any of those things .
Alright , but that 's {disfmarker} but that 's OK , and I mean it it 's again a kind of one minimal extension of the existing things .
You know , uh what are we going to use to make this decision {disfmarker}
Right and then , once we 've made the decision , how do we put that into the content ?
Yeah , so the pro The immediate problem is {disfmarker} is back t t to what you were {disfmarker} what you are doing with the belief - net .
So , the hardest problem is how are you going to get this information from some combination of the {disfmarker} what the person says and the context and the ontology .
uh , we have a d a technical problem with the belief - nets that we {disfmarker} we don't want all the com
too many factors if we {disfmarker} if we allow them to just go combinatorially .
but we also could do it um you know if we have a {disfmarker} a {disfmarker} a belief - net interface .
So the belief - net takes as input , a vector ,
And um it Output is whatever , as well .
But this information is just M - three - L ,
and then we want to look up some more stuff in the ontology
and we want to look up some more stuff in the {disfmarker}
maybe we want to ask the real world ,
maybe you want to look something up in the GRS ,
but also we definitely want to look up in the dialogue history um some s some stuff .
see what we 'd like to do , and {disfmarker} and this has been implicit in the discussion , is to do this in such a way that you get a lot of re - use .
So . What you 're trying to get out of this deep co cognitive linguistics is the fact that w if you know about source {disfmarker} source , paths and goals , and nnn {comment} all this sort of stuff , that a lot of this is the same , for different tasks .
And that {disfmarker} uh there 's {disfmarker} there 's some {disfmarker} some important generalities that you 're getting ,
u u What are the primitives , and how do you break this {disfmarker}
see what 's the really interesting question is can you use uh deep uh cognitive linguistics to {pause} get powerful generalizations .
So just from this local construction you know that you 're gonna hafta treat it as a container you might as well go off and get that information .
And that may effect the way you process everything else .
So if you say " how do I get into the castle "
Or , you know , " what is there in the castle " or {disfmarker}
so there 's all sorts of things you might ask that involve the castle as a container
and you 'd like to have this orthogonal so that anytime the castle 's referred to as a container , you crank up the appropriate stuff .
Independent of what the goal is , and independent of what the surrounding language is .
Alright , so that 's {disfmarker} that 's the {disfmarker} that 's the thesis level
