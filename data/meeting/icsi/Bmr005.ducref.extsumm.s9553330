Um , so , uh , he was interested in the question of {disfmarker} you know , relating to his {disfmarker} to the research he presented recently , um of inference structures ,
and uh , the need to build in , um , this {disfmarker} this sort of uh mechanism for understanding of language .
uh and one of the things I know that also came up uh is some discussions that {disfmarker} that uh {disfmarker} that uh Jane had with Lokendra
uh about some {disfmarker} some {disfmarker} some um uh work about
but anyway some {disfmarker} some potential collaboration there about {disfmarker} about the {disfmarker} about the {disfmarker} working with these data .
and um uh I thought that if we were going to project into the future when we had a lot of data , uh and um such things might be useful for that in or before we invested too much uh effort into that he should uh , with Jane 's help , look into some of the data that we 're {disfmarker} already have
and see , is there anything to this at all ?
Is there any point which you think that , you know , you could gain some advantage and some potential use for it .
Uh , he was {disfmarker} he {disfmarker} he {disfmarker} you know {disfmarker} We met and he was gonna go and uh you know , y look through them more systematically
and then uh meet again .
So I was just realizing we 've {disfmarker} You guys have been talking about " he " um for at least uh , I don't know , three {disfmarker} three four minutes without ever mentioning the person 's name again .
So this is {disfmarker} this is {disfmarker} this is {disfmarker} gonna be a big , big problem if you want to later do uh , you know , indexing , or speech understanding of any sort .
Um , I f f f I 've {disfmarker} @ @ {comment} d A minute {disfmarker} uh , several minutes ago , I , like , briefly was {disfmarker} was not listening
Yeah , there 's a lot of pronoun {disfmarker}
and {disfmarker} So who is " he " in this context ?
I probably been affect No , I th I think I 've been affected by too many conversations where we were talking about lawyers and talking about {disfmarker} and concerns about " oh gee is somebody going to say something bad ? " and so on .
And so I {disfmarker} so I 'm {disfmarker} I 'm tending to stay away from people 's names even though uh {disfmarker}
I was just {disfmarker} I was just {disfmarker} I was overreacting just because we 've been talking about it .
And in fact , it is {disfmarker} it is {disfmarker} it is sensitive .
I {disfmarker} I came up with something from the Human Subjects people that I wanted to mention .
You know , I asked her very specifically about this clause of how , um , you know , it says " no individuals will be identified
uh , " in any publication using the data . "
So I think it 's really {disfmarker} really kind of adaptive and wise to not mention names any more than we have to
because if there 's a slanderous aspect to it , then how much to we wanna be able to have to remove ?
Yeah . I mean we should do whatever 's natural in a meeting if {disfmarker} if we weren't being recorded .
Right , so I {disfmarker} So my behavior is probably not natural .
Well , we t we t we talked about this during the anon anonymization .
If we wanna go through and extract from the audio and the written every time someone says a name .
And I thought that our conclusion was that we didn't want to do that .
But a actually , I 'm sorry . I really would like to push {disfmarker} finish this off .
I {disfmarker} I remind that me {disfmarker} my first objective eh , in the project is to {disfmarker} to study difference parameters
to {disfmarker} to find a {disfmarker} a good solution to detect eh , the overlapping zone in eh speech recorded .
to {disfmarker} to find and to locate and to mark eh the {disfmarker} the different overlapping zone .
But eh , {vocalsound} tsk , {comment} {vocalsound} ehhh {comment} In that way {comment} I {disfmarker} {vocalsound} I {disfmarker} {vocalsound} I begin to {disfmarker} to study and to analyze the ehn {disfmarker} the recorded speech eh the different session
And eh so eh I was eh {disfmarker} I am transcribing the {disfmarker} the first session
and I {disfmarker} I have found eh , eh one thousand acoustic events ,
Eh almost eh three hundred eh in one session
How many overlaps were there uh in it ?
in five {disfmarker} eh in forty - five minutes .
When eh {vocalsound} eh I w I {disfmarker} {vocalsound} I was eh look at eh nnn , the difference speech file ,
um , for example , eh if eh we use the ehm {disfmarker} the mixed file , to {disfmarker} to transcribe , the {disfmarker} the events and the words , I {disfmarker} I saw that eh the eh speech signal , collected by the eh this kind of mike {disfmarker} eh of this kind of mike , eh are different from the eh mixed signal eh , we eh {disfmarker} collected by headphone .
I {disfmarker} I {disfmarker} I knew that eh the signal eh , eh would be different ,
but eh the {disfmarker} the problem is eh , eh we eh detected eh difference events in the speech file eh collected by {disfmarker} by that mike uh qui compared with the mixed file .
And so if {disfmarker} when you transcribe eh only eh using the nnn {disfmarker} the mixed file , it 's possible {disfmarker} eh if you use the transcription to evaluate a different system ,
it 's possible you eh {disfmarker} in the eh
i and you use the eh speech file collected by the eh fet mike , to eh {disfmarker} to nnn {disfmarker} to do the experiments {pause} with the {disfmarker} the system ,
its possible to evaluate eh , eh {disfmarker} or to consider eh acoustic events that {disfmarker} which you marked eh in the mixed file , but eh they don't appear in the eh speech signal eh collected by the {disfmarker} by the mike .
The {disfmarker} the reason that I generated the mixed file was for IBM to do word level transcription , not speech event transcription .
So I agree that if someone wants to do speech event transcription , that the mixed signals here {disfmarker}
Yeah , well , just {disfmarker} I mean , just in that {disfmarker} that one s ten second , or whatever it was , example that Adam had that {disfmarker} that we {disfmarker} we passed on to others a few months ago ,
there was that business where I g I guess it was Adam and Jane were talking at the same time
and {disfmarker} and uh , in the close - talking mikes you couldn't hear the overlap , and in the distant mike you could .
So yeah , it 's clear that if you wanna study {disfmarker} if you wanna find all the places where there were overlap , it 's probably better to use a distant mike .
On the other hand , there 's other phenomena that are going on at the same time for which it might be useful to look at the close - talking mikes ,
Um , obviously this is very , very time - consuming , and you 're finding lots of things
but in the interests of making progress , uh might I s
how {disfmarker} how would it affect your time if you only marked speaker overlaps ?
Do not mark any other events ,
Do you think that would speed it up quite a bit ?
Yeah sure .
Then I think it 's a good idea .
and it 's a g worthwhile thing to study ,
but obviously it takes a lot of time to mark all of these things .
Whereas th i I would think that uh you {disfmarker} we can study more or less as a distinct phenomenon the overlapping of people talking .
Now , why do you need to mark speaker overlap by hand if you can infer it from the relative energy in the {disfmarker}
So the idea was that what he was going to be doing was experimenting with different measures
such as the increase in energy , such as the energy in the LPC residuals , such as {disfmarker}
I mean there 's a bunch of things {disfmarker} I mean , increased energy is - is sort of an obvious one .
I mean , you could {disfmarker} you could do the dumbest thing and get {disfmarker} get it ninety percent of the time .
But when you start going past that and trying to do better , it 's not obvious what combination of features is gonna give you the {disfmarker} you know , the right detector .
So the idea is to have some ground truth first .
And so the i the idea of the manual marking was to say " OK this , i you know , it 's {disfmarker} it 's really here " .
You know , I did {disfmarker} I did uh something almost identical to this at one of my previous jobs , and it works pretty well .
I mean , i almost exactly what you described , an energy detector with a median filter , you look for runs .
um , that you can get the training data for pretty quickly is , you know ,
if you infer form the close - talking mikes where the on - off points are of speech ,
I 've {disfmarker} I 've written a program to do that ,
you know , how can we detect that from a far - field ?
It just takes a threshold , based on {disfmarker} on the volume ,
Or you can set the threshold low and then weed out the false alarms by hand .
um , and then it does a median filter , and then it looks for runs .
So , I think it was partly that , you know , give somebody a chance to actually look at the data and see what these are like , partly that we have e some ground truth to compare against , you know , when {disfmarker} when he {disfmarker} he gets his thing going ,
I was just thinking as a way to speed up you know , the amount of {disfmarker}
Was that um there m {pause} there was this already a script I believe uh that Dan had written , {comment} that uh handle bleedthrough ,
I mean cuz you have this {disfmarker} this close {disfmarker} you have contamination from other people who speak loudly .
It 's a cross - correlation filter .
And so I think doing that to generate these possibilities and then going through and saying yes or no on them would be a quick way to {disfmarker} to do it .
Although if you {disfmarker} if you have some parameters like what 's a good window size for the median filter {disfmarker}
Oh ! {comment} I have to remember .
I 'll think about it ,
and try to remember .
It was when I was working for the government .
Can I just ask about the data ,
like very straightforward question is where we are on the amount of data and the amount of transcribed data ,
Right so there 's this {disfmarker} this {disfmarker} There 's this forty - five minute piece that Jane transcribed .
That piece was then uh sent to IBM so they could transcribe so we have some comparison point .
Then there 's s a larger piece that 's been recorded and uh put on CD - ROM and sent uh to IBM .
That was about ten hours , and there was about {disfmarker}
Well , I haven't sent them yet because I was having this problem with the {pause} missing files .
H how many total have we recorded now , altogether ?
We 're saying about {pause} twelve hours .
About twelve {pause} by now . Twelve or thirteen .
Uh - huh . And we 're recording only this meeting , like continuously
we 're only recording this one now ? or {disfmarker} ?
No .
but there 's at least one meeting recorded of uh the uh uh natural language guys .
uh , we 've started having a morning meeting , today uh i starting a w a week or two ago , on the uh front - end issues ,
and we 're recording those ,
uh there 's a network services and applications group here who 's agreed to have their meetings recorded ,
is I have a bunch of scripts to help with the transcription of the digits .
We don't have to hand - transcribe the digits because we 're reading them and I have those .
I mean , is it something of interest ?
Yeah , whoever we have working on the acoustics for the Meeting Recorder are gonna start with that .
I mean , one of the things I wanted to do , uh , that I I talked to {disfmarker} to Don about , is one of the possible things he could do or m also , we could have someone else do it , is to do block echo cancellation ,
to try to get rid of some of the effects of the {disfmarker} the {disfmarker} the far - field effects .
Um , I mean we have {disfmarker} the party line has been that echo cancellation is not the right way to handle the situation
and so the tack that we 've taken is more " lets come up with feature approaches and multi - stream approaches and so forth , that will be robust to it for the recognizer and not try to create a clean signal " .
But it occurred to me a few months ago that uh party lines are always , you know , sort of dangerous .
It 's good {disfmarker} {vocalsound} good to sort of test them , actually .
And so we haven't had anybody try to do a good serious job on echo cancellation and we should know how well that can do .
So that 's something I 'd like somebody to do at some point , just take these digits , take the far - field mike signal , and the close uh mike signal , and apply really good echo cancellation .
Uh . Let 's see . I guess you {disfmarker} you actually already said this thing about the uh {disfmarker} about the consent forms ,
The a apparently {disfmarker} I mean , we 're gonna do a revised form , of course .
but once a person has signed it once , then that 's valid for a certain number of meetings .
So I think from a s practical standpoint , maybe we could have them do it once every ten meetings , or something .
So I was thinking , you know , we 've got the room set up
and you can always think of , also for political reasons , if ICSI collected you know , two hundred hours , that looks different than forty hours , even if we don't transcribe it ourselves ,
I mean , is there {disfmarker} Are there any other meetings here that we can record , especially meetings that have some kind of conflict in them {comment} or some kind of deci
uh , that have some more emotional aspects to them ,
um I 'm talking more about strong differences of opinion meetings ,
maybe with manager types , or {disfmarker}
Yeah . So {disfmarker} Yeah . So I {disfmarker} I {disfmarker} uh , I {disfmarker} I 'd mentioned to Adam , and {disfmarker} that was another thing I was gonna talk {disfmarker} uh , mention to them before {disfmarker} {comment} that uh there 's uh {disfmarker} It {disfmarker} it oc it occurred to me that we might be able to get some additional data by talking to uh acquaintances in local broadcast media .
Because , you know , we had talked before about the problem about using found data , {comment} that {disfmarker} that uh it 's just set up however they have it set up
But um , it did occur to me that we could go to friends in broadcast media and say " hey you have this panel show , {pause} or this {disfmarker} you know , this discussion show , and um can you record multi - channel ? "
and what we were gonna get from UW , you know , assuming they {disfmarker} they {disfmarker} they start recording , isn't {disfmarker} als also is not going to be this exact setup .
the other thing that occurred to me after we had that discussion , in fact , is that it 's even possible , since of course , many radio shows are not live , {comment} uh that we could invite them to have like some of their {disfmarker} {comment} record some of their shows here .
There 'd be no reason why a person couldn't get together several uh , you know , friends ,
and come and argue about a topic if they wanted to ,
if anyone knows of one more m or two more wee meetings per week that happen at ICSI , um that we could record , I think it would be worth it .
Yeah . Well , we should also check with Mari again , because they {disfmarker} because they were really intending , you know , maybe just didn't happen , but they were really intending to be duplicating this in some level .
One of the things that I think is a little {disfmarker} a little bit of a limitation , there is a think when the people are not involved uh in our work , we probably can't do it every week .
You know ? I {disfmarker} I {disfmarker} I {disfmarker} I think that {disfmarker} that people are gonna feel uh {disfmarker} are gonna feel a little bit constrained .
but um it does seem to me that we might be able to get subjects from campus to come down and do something that wouldn't be too artificial .
I mean , we could {disfmarker} political discussions , or {disfmarker} or something or other ,
And I {disfmarker} I d I do think that maybe we can get somewhere with the {disfmarker} with the radio .
Another thing we discussed was um that {disfmarker}
