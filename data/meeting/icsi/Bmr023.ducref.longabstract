The Berkley Meeting Recorder project is well underway , and this meeting discusses the progress and ongoing issues.
A pressing concern for the group is the DARPA meeting in July , which is only a short time away , and for which they would like to have some progress.
Specifically , the group would like to have transcripts available , which would mean resolving legal issues for data use and on the basis of feedback from IBM get more transcription underway.
Additionally they would also like to have the question answering mock-up and transcriber interface ready for then.
PLP results for the front-end look good , with the group also reporting progress in segmentation: Thilo's segmenter will now be used and ways of improving performance investigated;
The classifier segmentation is progressing well , especially in the use of prosody for identifying interruption.
Work on the front end continues , with improvements of 3-5% being made.
The group discussed how the digits should be recorded in the meeting.
In the end they decided to record these in unison for all of the meeting participants as a whole.
To improve the performance of Thilo's automatic segmenter , this is going to be retrained and adapted to run with Thilo's posteriors and speaker background models.
Regarding transcription , no new transcribers will be employed until situation regarding IBM is clarified.
Legal issues surrounding the approval and signing off of transcripts by participants has proved to be very complicated , and so will be sorted out off line by those involved by July.
After finding discrepancies with the CMU researchers , the ICSI group have decided to tune the size of their Gaussian system.
After raising the difficulty of checking for bugs in their generation of tandem features , they decide to check with Stephane who has more experience of these procedures.
For the DARPA meeting in July , the group propose that they should have the question answering mock-up and transcriber interface ready for then , and also have data available.
Unfortunately , there are legal issues regarding the approval of transcripts.
Additionally , the group would like to have their data transcriptions in "production mode" by then.
However the group do not want to hire more transcribers until IBM confirms in the next 2-3 weeks the acceptability of the data.
Segmentation for the recogniser has been done by hand which the group consider "cheating" , instead now they want to use Thilo's automatic segmenter.
The classifier segmentation work is going well , but needs more data to improve results since non-native speaker data cannot be used.
For the front-end , so far the group have been using a high number of Gaussians per cluster ( 64 ) rather than the ten per cluster used by researchers at CMU , therefore they need to tune their Gaussian system to the feature vector.
The group  observed that it would be difficult to check for bugs in the generation of tandem features for the SRI system.
Experimentation is taking place using different front-ends with the SRI recogniser.
This is not yet complete , but PLP results are improving to match those of MFCC , with vocal tract length normalisation working "beautifully" on a training set of 24 hours , and giving overall improvement of between 3 and 5%.
Thilo's automatic segmenter is now working , and although it has low precision , this is mediated by the high recall.
The group will send IBM another sample file to check that the beep problems are fixed , and this should take 2-3 weeks.
Progress on transcriptions has been made on 5 "set one" meetings , and two more transcribers set on.
Pre-segmentation has proved useful.
Meeting Recorder data of the 62 hours of meetings already analysed has been organised into a spreadsheet with the aim to make this available over the WWW.
Classifier segmentation is expected to give better results from more data: currently "cheating" using word features for forced alignment , but looking to use other data such as "spurts".
Prosodaic features looking promising for identifying interruptions.
Generally the ICSI data offers better pitch features and vowel voicing than the Switchboard corpus due to the use of close talking mikes rather than telephone handsets.
