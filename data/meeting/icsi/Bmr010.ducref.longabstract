The Berkeley Meeting Recorder group talked about the ongoing transcription effort and issues related to the Transcriber tool , which despite its limitations for capturing tight time markings for overlapping speech , will continue to remain in use.
Speaker mn014 explained his efforts to pre-segment the signal into speech and non-speech portions for facilitating transcriptions.
Recording equipment and procedures were discussed , with a focus on audible breathing and the need for standards in microphone wear and use.
And , finally , it was determined that speaker mn005's efforts to detect speaker overlap using energy should instead be focussed on pitch- and harmonicity-related features or be guided by a non-featural , statistical approach , i.e . via the use of Markov models.
In the interest of time , it was decided that the group should continue using the existing Transcriber tool and perform a forced alignment on the close-talking microphones that will , it is hoped , help to recover some of the time information indicating where different speaker overlaps occurred in the signal.
A meeting will be arranged with NIST to decide on a common standard and format for doing transcriptions.
One or two meetings will be assigned to multiple transcribers to check for inter-annotator agreement.
To cut down on audible breaths during recordings , the group will institute some level of standards for microphone wear and use.
Speaker mn005 will feed his hand-segmented data into the speech segmenter developed by Javier to train it to identify different types of speech ( i.e . that of single versus multiple speakers ) , as well as focussing on pitch- and harmonicity-related features for identifying overlapping speech.
There is no channel identifier to help in encoding speaker overlaps.
Speech uttered while laughing is problematic for ASR.
So far , speaker mn005's attempts to detect speaker overlap have been unsuccessful , as it has not been possible to normalize energy as a reliable indicator of overlap.
Speaker mn014's efforts to detect speech/non-speech portions in the mixed signal ( using an HMM-based detector with Gaussian mixtures ) have produced pre-segmentations that facilitate the transcription effort.
Speaker mn014 also trained the system to identify speech from loud versus quiet speakers.
Such pre-segmentation modifications allow the experimenter to specify the minimum length of speech and silence portions desired , and also facilitate the identification of pauses and utterance boundaries.
The transcriber pool is making quick progress , and may be used in the future to perform other types of coding , e.g . a more detailed analysis of speaker overlap.
Transcribers are coding non-speech gestures , such as audible breaths and laughter , both of which are useful for improving recognition results.
Recent modifications to the Transcriber tool allow transcribers to listen to speech from different channels , as well as helping to preserve portions of overlapping speech , and enabling the creation of different output files for each channel for a cleaner and more segmentable transcript.
The Praat software package was discussed as an alternative transcription tool capable of representing multiple channels of speech.
Cross-correlation was discussed as a means of enabling speaker identification , and may be integrated into future work.
