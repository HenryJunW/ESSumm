so {pause} Basically , {vocalsound} um {pause} as you know , uh {pause} part of the encoding {pause} includes a mark that indicates {pause} an overlap .
It 's not indicated {pause} with , um {pause} uh , tight precision , it 's just indicated that {disfmarker} OK , so , It 's indicated to {disfmarker} to {disfmarker} so the people know {pause} what parts of sp which {disfmarker} which stretches of speech were in the clear , versus being overlapped by others .
And , um {pause} What you can see is the number of overlaps {pause} and then {pause} to the right , {pause} whether they involve two speakers , three speakers , or more than three speakers .
And , {pause} um {pause} and , what I was looking for sp sp specifically was the question of {pause} whether they 're distributed evenly throughout or whether they 're {pause} bursts of them .
uh , you know {disfmarker} y this is just {disfmarker} {pause} eh {disfmarker} eh , this would {disfmarker} this is not statistically {pause} verified , {pause} but it {pause} did look to me as though there are bursts throughout , rather than being {pause} localized to a particular region .
The part down there , where there 's the maximum number of {disfmarker} {pause} of , um {pause} overlaps is an area where we were discussing {pause} {vocalsound} whether or not it would be useful to indi to s to {pause} code {pause} stress , {pause} uh , sentence stress {pause} as possible indication of , uh {pause} information retrieval .
Now , {pause} Another question is {pause} is there {disfmarker} are there {pause} individual differences in whether you 're likely to be overlapped with or to overlap with others .
I , you know , my {disfmarker} I had this script {pause} figure out , um {pause} who {pause} was the first speaker , who was the second speaker involved in a two - person overlap , I didn't look at the ones involving three or more .
And , {pause} then if you look down in the summary table , {pause} then you see that , um {pause} th they 're differences in {pause} whether a person got overlapped with or {pause} overlapped by .
Raw counts .
so . Of the times a person spoke and furthermore was involved in a two two - person overlap , {vocalsound} {vocalsound} what percentage of the time were they the overlapper and what percent of the time were they th the overlappee ?
um , {pause} that some people tend to be overlapped {pause} with more often than they 're overlapped ,
but , of course , uh i e {vocalsound} this is just one meeting , {pause} uh {pause} there 's no statistical testing involved , and that would be {pause} required for a {disfmarker} for a finding {pause} of {pause} any {pause} kind of {pause} scientific {pause} reliability .
And actually , {pause} you know , the point is not about an individual , it 's the point about {pause} tendencies toward {pause} you know , different styles , different speaker styles .
And {pause} it would be , you know {pause} of course , {pause} there 's also the question of what type of overlap was this , and w what were they ,
and i and I {disfmarker} and I know that I can distinguish at least three types and , probably more ,
So , um Then it beco {pause} though {disfmarker} so {disfmarker} just {disfmarker} just superficially to give {pause} um {pause} a couple ideas of the types of overlaps involved , I have at the bottom several that I noticed .
So , {pause} {vocalsound} uh , there are backchannels , like what Adam just did now
and , um {pause} {vocalsound} um , anticipating the end of a question and {pause} simply answering it earlier ,
And places {pause} also which I thought were interesting , where two or more people gave exactly th the same answer in unison {disfmarker} different words of course
So , uh , the point is that , um {pause} {vocalsound} overlap 's not necessarily a bad thing and that it would be im {pause} i useful to subdivide these further and see if there are individual differences in styles with respect to the types involved .
Well , of course th the biggest , {pause} um {pause} result here , which is one we 've {disfmarker} {pause} we 've talked about many times and isn't new to us , but which I think would be interesting to show someone who isn't familiar with this {vocalsound} {pause} is just the sheer number of overlaps .
it 's a forty {disfmarker} {pause} forty plus minute {pause} {vocalsound} meeting ,
here 's a relatively short meeting ,
and not only were there two hundred and fifteen overlaps {vocalsound} {pause} but , {pause} uh I think there 's one {disfmarker} {pause} one minute there where there {disfmarker} where {disfmarker} where there wasn't any overlap ?
The duration is , uh {pause} the variation {disfmarker} the variation of the duration is uh , very big on the dat
but , uh {pause} I {disfmarker} I will , uh I will do the {disfmarker} the study of the {disfmarker} {pause} with the {disfmarker} with the program with the {disfmarker} uh , the different , uh {pause} the , nnn , {pause} distribution of the duration of the overlaps .
It 'd be interesting to see what the total amount of time is in the overlaps , versus {disfmarker}
Uh , so {pause} le let 's think about the case where {vocalsound} A starts speaking {pause} {vocalsound} and then B overlaps with A , {pause} and then the minute boundary happens .
And let 's say that {vocalsound} after that minute boundary , {vocalsound} um {pause} B is still speaking , {pause} and A overlaps {pause} with B ,
that would be a new overlap .
But otherwise {pause} um , let 's say B {pause} comes to the conclusion of {disfmarker} of that turn without {pause} anyone overlapping with him or her ,
in which case there would be no overlap counted in that second minute .
We just haven't done th the precise second to sec you know , {pause} second to second coding of when they occur .
So , um {pause} we talked over the minute boundary .
Is this {pause} considered as one overlap in each of the minutes , the way you have done this .
No , it wouldn't .
It would be considered as an overlap in the first one .
Other - otherwise you 'd get double counts , here and there .
Cuz i i I find it interesting that there were a large number of overlaps and they were all two - speaker .
So , the question is , you know , how many more overlaps {pause} {vocalsound} do you have {pause} of , say the two - person type , by adding more people . to a meeting ,
But what I mean is {vocalsound} that , um in Switchboard , {pause} despite the many {disfmarker} many other problems that we have , one problem that we 're not considering is overlap .
And what we 're doing now is , {pause} aside from the many other differences in the task , we are considering overlap
and one of the reasons that we 're considering it , {pause} you know , one of them not all of them , one of them is {vocalsound} that w uh at least , {pause} you know I 'm very interested in {vocalsound} the scenario in which , uh {pause} both people talking are pretty much equally {pause} audible , {vocalsound} and from a single microphone .
And so , {pause} in that case , it does get mixed in , {vocalsound} and it 's pretty hard to jus {pause} to just ignore it , to just do processing on one and not on the other .
So it may be that having three people {pause} {vocalsound} is very different from having two people or it may not be .
I {disfmarker} I agree that it 's an issue here {pause} but it 's also an issue for Switchboard
so , from the point of view of studying dialogue , I mean , which {pause} Dan Jurafsky and Andreas and I had some projects on , you want to know the sequence of turns .
So what happens is if you 're talking and I have a backchannel in the middle of your turn , and then you keep going what it looks like in a dialogue model is your turn and then my backchannel ,
even though my backchannel occurred completely inside your turn .
So , for things like language modeling or dialogue modeling {pause} {vocalsound} it 's {disfmarker} We know that that 's wrong in real time .
But , because of the acoustic segmentations that were done and the fact that some of the acoustic data in Switchboard were missing , people couldn't study it ,
It 's important to distinguish {pause} that , you know , this project {pause} is getting a lot of overlap {pause} but other projects were too , but we just couldn't study them .
what we 've learned about is overlaps in this situation , is that {disfmarker} the first {disfmarker} {pause} the first - order thing I would say is that there 's a lot of them .
In fact {disfmarker} {vocalsound} and it 's not just an overlap {disfmarker} bunch of overlaps {disfmarker} second - order thing is {vocalsound} it 's not just a bunch of overlaps in one particular point , {vocalsound} but that there 's overlaps , uh throughout the thing .
But we should still be able to somehow say what {disfmarker} what is the added contra contribution to sort of overlap time of each additional person , or something like that .
I mean , if a truck goes rolling past , {vocalsound} adults will well , depending , but mostly , adults will {disfmarker} will {disfmarker} {pause} will hold off to what {disfmarker} {pause} to finish the end of the sentence till the {disfmarker} till the noise is past .
And I think we generally do {vocalsound} monitor things like that , {pause} about {disfmarker} whether we {disfmarker} whether our utterance will be in the clear or not .
And partly it 's related to rhythmic structure in conversation ,
And {disfmarker} and , just to finish this , that um That I think that {vocalsound} there may be an upper bound on how many overlaps you can have , simply from the standpoint of audibility and how loud the other people are who are already {pause} in the fray .
Now if it 's just backchannels , {vocalsound} people {pause} may be doing that {pause} with less {pause} intention of being heard , {pause} just sort of spontaneously doing backchannels ,
in which case {pause} that {disfmarker} those might {disfmarker} there may be no upper bound on those .
So {disfmarker} so actually , um That 's in part because the nodding , if you have visual contact , {pause} the nodding has the same function ,
Um {pause} no , when {disfmarker} when {disfmarker} when there 's backchannel , I mean , just {disfmarker} I was just listening , and {disfmarker} and when there 's two people talking and there 's backchannel it seems like , {pause} um the backchannel happens when , you know , the pitch drops and the first person {disfmarker}
I think there 's a lot of the kind that Jose was talking about , where {disfmarker} {pause} I mean , this is called " precision timing " in {pause} conversation analysis , where {pause} {vocalsound} they come in overlapping , {pause} but at a point where the {pause} information is mostly {pause} complete .
So all you 're missing is some last syllables or something or the last word or some highly predictable words .
So technically , it 's an overlap .
But {pause} you know , from information flow point of view it 's not an overlap in {pause} the predictable information .
Language model prediction of overlap , that would be really interesting .
Well , that 's exactly , exactly why we wanted to study the precise timing of overlaps ins in uh Switchboard ,
Uh , to distinguish between , say , backchannels {vocalsound} {pause} precision timing {disfmarker} Sort of {vocalsound} you know , benevolent overlaps , and {disfmarker} and {disfmarker} {vocalsound} {pause} and w and {disfmarker} and sort of , um {pause} I don't know , hostile overlaps , where {vocalsound} someone is trying to grab the floor from someone else .
So {disfmarker} so here 's a {disfmarker} here 's a first interesting {pause} labeling task .
These were {disfmarker} these were {pause} benevolent types , as people {pause} finishing each other 's sentences , and {pause} stuff .
I have a feeling most of these things are {disfmarker} that {disfmarker} {pause} that are not {pause} a benevolent kind are {disfmarker} are {vocalsound} {pause} are , uh {pause} um {pause} {vocalsound} are {disfmarker} are competitive as opposed to real really {disfmarker} really hostile .
You know , the other thing I was thinking was that , {pause} um {pause} these {disfmarker} all these interesting questions are , of course , pretty hard to answer with , uh u {pause} you know , a small amount of data .
I mean {vocalsound} we {disfmarker} most of our meetings are {pause} uh , meetings currently with say five , six , seven , eight people
Should we {pause} really try to have some two - person meetings , {pause} or some three - person meetings and re record them {vocalsound} just to {disfmarker} to {disfmarker} to beef up the {disfmarker} the statistics on that ?
If {disfmarker} if the goal were to just look at overlap you would {disfmarker} you could serve yourself {disfmarker} save yourself a lot of time but not even transcri transcribe the words .
Well , I was thinking you should be able to do this from the {pause} acoustics , on the close - talking mikes ,
I guess my {disfmarker} my first comment was , um {pause} only that {vocalsound} um we should n not attribute overlaps only to meetings ,
but that {vocalsound} in normal conversation with two people there 's an awful lot of the same kinds of overlap ,
and that it would be interesting to look at {pause} whether there are these kinds of constraints that Jane mentioned , that {vocalsound} what maybe the additional people add to this competition that happens right after a turn ,
To answer your question I {pause} it {disfmarker} I don't think it 's crucial to have controls
but I think it 's worth recording all the meetings we {pause} can .
we have {disfmarker} have in the past and I think continue {disfmarker} will continue to have a fair number of {pause} uh phone conference calls .
And , {vocalsound} uh , {pause} and as a {disfmarker} to , um {vocalsound} as another c {pause} c comparison {pause} condition , {pause} we could um see what {disfmarker} what what happens in terms of overlap , when you don't have visual contact .
Well , we 're not really set up for it {pause} to do that .
Or , this is getting a little extravagant , we could put up some kind of blinds or something to {disfmarker} {pause} to remove , uh {pause} visual contact .
weren't we gonna take a picture {pause} at the beginning of each of these meetings ?
Um , what {disfmarker} I had thought we were gonna do is just take pictures of the whiteboards . rather than take pictures of the meeting .
The {disfmarker} because you get then the spatial relationship of the speakers .
Well , you could do that by just noting on the enrollment sheet the {disfmarker} {pause} the seat number .
Seat number , that 's a good idea .
I 'll do that on the next set of forms .
So I 'm gonna put little labels on all the chairs with the seat number .
Put them {disfmarker} {pause} Like , {pause} put them on the table where they {disfmarker}
Yeah , I 've been playing with , um uh , using the close - talking mike to do {disfmarker} to try to figure out who 's speaking .
So my first attempt was just using thresholding and filtering , that we talked about {disfmarker} about two weeks ago ,
So if you fiddle around with it a little bit and you get good numbers you can actually do a pretty good job of segmenting when someone 's talking and when they 're not .
But if you try to use the same paramenters on another speaker , it doesn't work anymore ,
even if you normalize it based on the absolute loudness .
It does work for the one speaker throughout the whole meeting .
The algorithm was , uh take o every frame that 's over the threshold , and then median - filter it , {vocalsound} and then look for runs .
So there was a minimum run length ,
So you take a {disfmarker} each frame , and you compute the energy
and if it 's over the threshold you set it to one , and if it 's under the threshold you set it to zero , {vocalsound} so now you have a bit stream {pause} of zeros and ones .
And then I median - filtered that {vocalsound} using , um {pause} a fairly long {pause} filter length .
Uh {pause} well , actually I guess depends on what you mean by long , you know , tenth of a second sorts of numbers .
Um and that 's to average out you know , pitch , you know , the pitch contours , and things like that .
And then , uh looked for long runs .
And that works O K , if you fil if you tune the filter parameters , if you tune {vocalsound} how long your median filter is and how high you 're looking for your thresholds .
OK and then the other thing I did , was I took {vocalsound} Javier 's speaker - change detector {disfmarker} acoustic - change detector , and I implemented that with the close - talking mikes ,
and {pause} unfortunately that 's not working real well , and it looks like it 's {disfmarker}
the problem is {disfmarker} he does it in two passes ,
the first pass {vocalsound} is to find candidate places to do a break .
And he does that using a neural net doing broad phone classification and he has the {vocalsound} the , uh {pause} one of the phone classes is silence .
And then he has a second pass which is a modeling {disfmarker} a Gaussian mixture model .
Um looking for {vocalsound} uh {vocalsound} whether it improves or {disfmarker} or degrades to split at one of those particular places .
And what looks like it 's happening is that the {disfmarker} even on the close - talking mike the broad phone class classifier 's doing a really bad job .
Um {pause} So , at any rate , my next attempt , {pause} which I 'm in the midst of and haven't quite finished yet was actually using the {vocalsound} uh , thresholding as the way of generating the candidates .
And then feeding that into the acoustic change detector .
But all of this is close - talking mike ,
So {pause} s my intention for this is {disfmarker} is as an aide for ground truth .
um {pause} H how are you going to adapt whatever you can very quickly learn about the new data ? {vocalsound} Uh , if it 's gonna be different from old data that you have ?
And I think that 's a problem {pause} with this .
Well , also what I 'm doing right now is not intended to be an acoustic change detector for far - field mikes .
What I 'm doing {vocalsound} is trying to use the close - talking mike {vocalsound} and just use {disfmarker} {pause} Can - and just generate candidate and just {pause} try to get a first pass at something that sort of works .
but , um {pause} I can imagine {pause} uh building {pause} a {pause} um {pause} model of speaker change {pause} detection {pause} that {vocalsound} takes into account {pause} both the far - field and the {vocalsound} uh {pause} actually , not just the close - talking mike for that speaker , but actually for all of th {pause} for all of the speakers .
But I also wanted to find threshold {disfmarker} uh , excuse me , mol overlap .
I was thinking about doing that originally to find out {pause} who 's the loudest ,
but {vocalsound} uh , what if you were just looking at very simple measures like energy measures but you don't just compare it to some threshold {pause} overall but you compare it to the {vocalsound} energy in the other microphones .
but I {disfmarker} I think what I was s nnn noting just when he {disfmarker} when Andreas raised that , was that there 's other information to be gained from looking at all {vocalsound} of the microphones and you may not need to look at very sophisticated things ,
I {disfmarker} I think it 's {disfmarker} it 's difficult , um {vocalsound} {pause} only to en with energy to {disfmarker} to consider that in that zone We have eh , eh , overlapping zone Eh , if you process only the the energy of the , of each frame .
It 'll be too hard to make barriers , I was thinking because they have to go all the way
so we need a barrier that doesn't disturb {pause} the sound ,
So this is the things that I think we did {vocalsound} in the last three months
Um {pause} in no particular order {vocalsound} uh , one , uh , ten more hours of meeting r meetings recorded , something like that , you know from {disfmarker} from , uh {pause} three months ago .
Um , pilot data put together and sent to IBM for transcription ,
uh {pause} next batch of recorded data put together on the CD - ROMs for shipment to IBM ,
Um {pause} human subjects approval on campus , uh {pause} and release forms worked out
so the meeting participants have a chance to request audio pixelization of selected parts of the spee their speech .
Um {vocalsound} audio pixelization software written and tested .
Um {pause} {vocalsound} preliminary analysis of overlaps in the pilot data we have transcribed ,
and exploratory analysis of long - distance inferences for topic coherence , that was {disfmarker} I was {disfmarker} {pause} wasn't {pause} sure if those were the right way {disfmarker} {pause} that was the right way to describe that because of that little exercise that {disfmarker} that you {comment} and {disfmarker} and Lokendra did .
Wh - what is " audio pixelization " ?
It 's just , uh {pause} beeping out parts that you don't want included in the meeting
I think {disfmarker} what I {disfmarker} what this has , uh , caused me {disfmarker} so this discussion caused me to wanna subdivide these further .
I 'm gonna take a look at the , uh {pause} backchannels ,
how much we have anal I hope to have that for next time .
